library(phangorn)
library(bayestraitr)
ie_gen_set <- read_excel("lex_gen/IE_Gender_set_24.03.2024.xlsx") %>%
rename(Glottocode = GlottoCode)
ie_sem_prop <- read_excel("lex_gen/Semantic_properties_final_24032024.xlsx")%>%
rename(Glottocode = GlottoCode)
# read all the tree files
files <- list.files("data_raw/all_trees/")
# read the first tree
trees <- ape::read.tree(paste0("data_raw/all_trees/",files[1]))  %>%
as.multiPhylo()
# read all the other trees
for(i in 2:length(files)){
# read the tree and merge it with the nexus
trees <- c(trees,
ape::read.tree(paste0("data_raw/all_trees/",
files[i]))) %>%
# save as multiphylo object
as.multiPhylo()
}
############PHYSICAL WORLD##############
phywo <- ie.lex %>%
filter(SemClass == "PHYSICAL WORLD") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace(., is.na(.), "-") #BayesTraits requires this format for NAs
# read the data for Indo-European
ie.lex <- ie_gen_set %>%
# only take the columns we want
select("Glottocode", "Concept", "Gender", "Semantic Classification") %>%
rename(SemClass = 'Semantic Classification') %>%
# assign all genders into a new gender column as 4 values of the same variable
mutate(Gender = replace(Gender, Gender == "m", 1)) %>%
mutate(Gender = replace(Gender, Gender == "f", 2)) %>%
mutate(Gender = replace(Gender, Gender == "n", 3)) %>%
mutate(Gender = replace(Gender, Gender == "c", 4)) %>%
mutate(Gender = replace(Gender, Gender == "NONE", 0)) %>%
# change to data frame
as.data.frame() %>%
drop_na() #remove NAs
fruit <- ie.lex %>%
filter(SemClass == "FRUIT") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace_na(list(apple = "-", grape = "-")) #BayesTraits requires this format for NAs
write_tsv(fruit, "lex_gen/data/fruit.txt")
fruit
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% fruit$Glottocode])
weap <- ie.lex %>%
filter(SemClass == "WEAPON") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace_na(list(arrow = "-", axe = "-", bow = '-', spear = '-', sword = '-')) #BayesTraits requires this format for NAs
write_tsv(weap, "lex_gen/data/weapon.txt")
weap
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% season$Glottocode])
# re-arrange the order of tip.labels so that they match across trees
trees_ie <- .compressTipLabel(trees_ie)
# random check that they match
all.equal(trees_ie[[1]]$tip.label, trees_ie[[5]]$tip.label)
# write the sample of trees
writeNexus(trees_ie %>% .uncompressTipLabel(),
"lex_gen/trees/season_tree.nex")
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% season$Glottocode])
############SEASON##############
season <- ie.lex %>%
filter(SemClass == "SEASON") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace(., is.na(.), "-") #BayesTraits requires this format for NAs
season
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% season$Glottocode])
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% season$Glottocode])
# only keep data for which we have the tree
data.phy.ie <- season %>% filter(Glottocode %in% trees_ie[[1]]$tip.label)
# re-arrange the order of tip.labels so that they match across trees
trees_ie <- .compressTipLabel(trees_ie)
# random check that they match
all.equal(trees_ie[[1]]$tip.label, trees_ie[[5]]$tip.label)
# write the sample of trees
writeNexus(trees_ie %>% .uncompressTipLabel(),
"lex_gen/trees/season_tree.nex")
############VEHICLE##############
vehicle <- ie.lex %>%
filter(SemClass == "VEHICLE") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace(., is.na(.), "-") #BayesTraits requires this format for NAs
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% vehicle$Glottocode])
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% vehicle$Glottocode])
# only keep data for which we have the tree
data.phy.ie <- vehicle %>% filter(Glottocode %in% trees_ie[[1]]$tip.label)
# re-arrange the order of tip.labels so that they match across trees
trees_ie <- .compressTipLabel(trees_ie)
# random check that they match
all.equal(trees_ie[[1]]$tip.label, trees_ie[[5]]$tip.label)
# write the sample of trees
writeNexus(trees_ie %>% .uncompressTipLabel(),
"lex_gen/trees/vehicle_tree.nex")
############MATERIAL##############
material <- ie.lex %>%
filter(SemClass == "MATERIAL") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace(., is.na(.), "-") #BayesTraits requires this format for NAs
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% material$Glottocode])
# create tree per concept
trees_ie <- drop.tip.multiPhylo(trees,
trees[[1]]$tip.label[!trees[[1]]$tip.label %in% material$Glottocode])
# only keep data for which we have the tree
data.phy.ie <- material %>% filter(Glottocode %in% trees_ie[[1]]$tip.label)
# re-arrange the order of tip.labels so that they match across trees
trees_ie <- .compressTipLabel(trees_ie)
# random check that they match
all.equal(trees_ie[[1]]$tip.label, trees_ie[[5]]$tip.label)
# write the sample of trees
writeNexus(trees_ie %>% .uncompressTipLabel(),
"lex_gen/trees/material_tree.nex")
############DOMESTIC ANIMAL##############
domanim <- ie.lex %>%
filter(SemClass == "DOMESTIC ANIMAL") %>% #retain only the concept of interest
select(-SemClass) %>% #delete unnecessary column
distinct() %>% #get rid of duplicate rows. This is a necessary step for the next line to work.
pivot_wider(names_from = Concept, values_from = Gender, values_fn = first) %>% #split the Concept columns into a column per concept, with the Gender values.
replace(., is.na(.), "-") #BayesTraits requires this format for NAs
library(brms)
library(dplyr)
library(tidyverse)
require(lingtypology)
library(plotrix)
library(TTR)
library(reshape2)
library(tidybayes)
library(tidyverse)
library(bayestestR)
library(tidyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(bayesplot)
library(ggpubr)
library(testthat)
library(cmdstanr)
setwd("/Users/noor/Documents/GitHub/Oldest-attested-languages")
##Import data for the Ancient Near East
#load Ancient Near East data
anea<- read.csv("data/anea.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"), check.names=FALSE)
semitic<- read.csv("data/Semitic.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"), check.names=FALSE)
##change names of duplicate languages, to not crash the recoding code
semitic[semitic == "Amharic"] <- "AmharicS"
semitic[semitic == "Egyptian Arabic"] <- "Egyptian ArabicS"
semitic[semitic == "Modern Hebrew"] <- "Modern HebrewS"
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
setwd("/Users/noor/Documents/GitHub/Oldest-attested-languages-in-the-Ancient-Near-East")
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
variables <- colnames(reg_data)[7:76]
#the code collects all the posterior draws from the area coefficient,
#i.e. indirectly quantifying the probability to observe the associated
#feature in the area. The coefficient column says which variable and category it is.
data<- read.csv("data/Processed_data/reg_data.csv")
#the code collects all the posterior draws from the area coefficient,
#i.e. indirectly quantifying the probability to observe the associated
#feature in the area. The coefficient column says which variable and category it is.
#data<- read.csv("data/Processed_data/reg_data.csv")
results<- readRDS("reg_results.rds")
variables <- colnames(reg_data)[7:76]
results.list <- list()
ex.prior <- c(prior_string("normal(0,1)", class="b"))
options(brms.backend = "cmdstanr")
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
reg_data
##Import data for the Ancient Near East
#load Ancient Near East data
anea<- read.csv("data/anea.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"), check.names=FALSE)
semitic<- read.csv("data/Semitic.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"), check.names=FALSE)
##change names of duplicate languages, to not crash the recoding code
semitic[semitic == "Amharic"] <- "AmharicS"
semitic[semitic == "Egyptian Arabic"] <- "Egyptian ArabicS"
semitic[semitic == "Modern Hebrew"] <- "Modern HebrewS"
#get data for worldwide sample
#get AUTOTYP data
#The data is taken from AUTOTYP version 0.1.2
#get AUTOTYP data
# load the dataset
load("data/autotyp.RData")
npag<- unnest(NPStructure, NPStructureAgreement, keep_empty = TRUE)
npagr<- select(npag, Glottocode, NPStructureAgreementCategory)
np<- select(NPStructure, Glottocode, NPStructureMarkingAssignmentType, NPStructureHeadlessness)
cl<- select(ClauseLinkage, Glottocode, ClausePosition)
nc<- select(NumeralClassifiers, Glottocode, NumeralClassifiersCount)
al<- select(AlignmentForDefaultPredicatesPerLanguage, Glottocode, DominantAlignment2ForCase)
vs<- select(VerbSynthesis, Glottocode, VerbInflectionMaxCategoryCount)
autotyp<- full_join(npagr, np, by='Glottocode')
autotyp<- full_join(autotyp, cl, by='Glottocode')
autotyp<- full_join(autotyp, nc, by='Glottocode')
autotyp<- full_join(autotyp, al, by='Glottocode')
autotyp<- full_join(autotyp, vs, by='Glottocode')
autotyp <- autotyp %>% distinct(Glottocode, .keep_all = T)
colnames(autotyp)[which(colnames(autotyp) == 'Glottocode')] <- 'glottocode'
#get WALS data
f_names <- c("24a","27a","30a","32a","33a","37a","38a","41a","42a","43a","44a","46a",
"47a","48a","52a","53a","54a","57a","59a","63a","64a","65a","66a","67a",
"70a","71a","73a","81a","84a","85a","86a","87a","88a","89a","90a","91a",
"92a","93a","101a","102a","106a","107a","112a","143a")
wals <- wals.feature(f_names)
variables <- colnames(reg_data)[7:76]
results.list <- list()
ex.prior <- c(prior_string("normal(0,1)", class="b"))
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
#get WALS data
f_names <- c("24a","27a","30a","32a","33a","37a","38a","41a","42a","43a","44a","46a",
"47a","48a","52a","53a","54a","57a","59a","63a","64a","65a","66a","67a",
"70a","71a","73a","81a","84a","85a","86a","87a","88a","89a","90a","91a",
"92a","93a","101a","102a","106a","107a","112a","143a")
wals <- wals.feature(f_names)
colnames(wals)[4:47] <- c("Locus of Marking in Possessive Noun Phrases",	"Reduplication", "Number of Genders", "Systems of Gender Assignment",  "Nominal Plurality",	"Definite Articles",	"Indefinite Articles",	"Distance Contrasts in Demonstratives", "Pronominal and Adnominal Demonstratives", "Third Person Pronouns and Demonstratives",  "Gender Distinctions in Independent Personal Pronouns",	"Indefinite Pronouns",	"Intensifiers and Reflexive Pronouns", "Person Marking on Adpositions",	"Comitatives and Instrumentals",	"Ordinal Numerals",	"Distributive Numerals", "Position of Pronominal Possessive Affixes",	"Possessive Classification",	"Noun Phrase Conjunction", "Nominal and Verbal Conjunction",	"Perfective/Imperfective Aspect",	"Past Tense",	"Future Tense", "Morphological Imperative",	"Prohibitive",	"Optative",	"Word Order", "Order of Object, Oblique, Verb", "Order of Adposition and Noun Phrase", "Order of Genitive and Noun",	"Order of Adjective and Noun", "Order of Demonstrative and Noun",	"Order of Numeral and Noun",	"Order of Relative Clause and Noun", "Order of Degree Word and Adjective",	"Position of Polar Question Particles",	"Position of Interrogative Phrases in Content Questions",	"Expression of Pronominal Subjects", "Verbal Person Marking",	"Reciprocal Constructions",	"Passive Constructions", "Negative Morphemes",	"Order of Negative Morpheme and Verb")
wals <- wals %>% distinct(language, .keep_all = T)
#get metadata
autotypmeta<- select(Register, Glottocode, Area, MajorBranch)
colnames(autotypmeta)[which(colnames(autotypmeta) == 'Glottocode')] <- 'glottocode'
colnames(autotypmeta)[which(colnames(autotypmeta) == 'Area')] <- 'area'
colnames(autotypmeta)[which(colnames(autotypmeta) == 'MajorBranch')] <- 'family'
#combine datasets
autotyp <- merge(autotyp, autotypmeta, by= "glottocode", all.x = T)
wals <- merge(wals, autotypmeta, by= "glottocode", all.x = T)
reference <- merge(wals, autotyp, all = T, by = c('glottocode', 'area', 'family'))
reference <- relocate(reference, language)
reference<- select(reference, -wals.code)
non_feature_columns <- -c(1:6)
#language threshold
feature_names<- c("Locus.of.Marking.in.Possessive.Noun.Phrases",	"Reduplication", "Gender.n", "Systems.of.Gender.Assignment",  "Nominal.Plurality",	"Definite.Articles",	"Indefinite.Articles",	"Distance.Contrasts.in.Demonstratives", "Pronominal.and.Adnominal.Demonstratives",	"Third.Person.Pronouns.and.Demonstratives",  "Gender.Distinctions.in.Independent.Personal.Pronouns",	"Indefinite.Pronouns",	"Intensifiers.and.Reflexive.Pronouns", "Person.Marking.on.Adpositions",	"Comitatives.and.Instrumentals",	"Ordinal.Numerals",	"Distributive.Numerals", "Position.of.Pronominal.Possessive.Affixes",	"Possessive.Classification",	"Noun.Phrase.Conjunction", "Nominal.and.Verbal.Conjunction",	"Perfective.Imperfective.Aspect",	"The.Past.Tense",	"The.Future.Tense", "The.Morphological.Imperative",	"The.Prohibitive",	"Optative",	"WordOrderSOV", "Order.of.Object..Oblique..and.Verb", "Order.of.Adposition.and.Noun.Phrase",	"Order.of.Genitive.and.Noun",	"Order.of.Adjective.and.Noun", "Order.of.Demonstrative.and.Noun",	"Order.of.Numeral.and.Noun",	"Order.of.Relative.Clause.and.Noun", "Order.of.Degree.Word.and.Adjective",	"Position.of.Polar.Question.Particles",	"Position.of.Interrogative.Phrases.in.Content.Questions",	"Expression.of.Pronominal.Subjects", "Verbal.Person.Marking",	"Reciprocal.Constructions",	"Passive.Constructions", "Negative.Morphemes",	"Order.of.Negative.Morpheme.and.Verb", "NPStructureAgreementCategory", "NPStructureMarkingAssignmentType", "NPStructureHeadlessness", "ClausePosition", "NumeralClassifiersCount", "DominantAlignment2ForCase", "VerbInflectionMaxCategoryCount", "glottocode", "language", "family", "longitude", "latitude")
#reference.data <- reference[,colnames(reference) %in% feature_names]
reference.data <- reference
reference.data$feature.sum<- rowSums(1*!is.na(as.matrix(reference.data[,non_feature_columns])))
reference.data <- reference.data %>% group_by(language) %>%
mutate(max_features = case_when(feature.sum == max(feature.sum) ~ 1, TRUE ~ 0)) %>%
filter(max_features == 1)
reference.data <- reference.data[-which(duplicated(reference.data$language)),]
#make a 100 language sample of the languages with most data
reference.data.order <- reference.data  %>% arrange(desc(feature.sum)) #order by amount of data
top.100 <- reference.data.order[1:100,] #keep top 100 languages with the most data
lang.samp <- top.100 %>% arrange(language)
lang.samp <- select(lang.samp, -feature.sum, -max_features)
lang.samp$area <- 0
lang.samp <- relocate(lang.samp, area, .after = family)
lang.samp<- as.data.frame(lang.samp)
#Combine Ancient Near East Data with worldwide data
combined_data<- merge(anea, lang.samp, all = TRUE)
combined_data<- merge(combined_data, semitic, all = TRUE)
combined_data[combined_data == ""] <- NA
###recode WALS features with 'mixed' category
#rename data to match names in recoding-patterns
wals_source_data<- combined_data
colnames(wals_source_data)[7:50]<- c("52A Comitatives and Instrumentals", "63A Noun Phrase Conjunction", "64A Nominal and Verbal Conjunction", "37A Definite Articles", "38A Indefinite Articles", "101A Expression of Pronominal Subjects", "46A Indefinite Pronouns", "43A Third Person Pronouns and Demonstratives", "41A Distance Contrasts in Demonstratives",
"42A Pronominal and Adnominal Demonstratives", "47A Intensifiers and Reflexive Pronouns", "44A Gender Distinctions in Independent Personal Pronouns", "32A Systems of Gender Assignment", "30A Number of Genders",
"112A Negative Morphemes", "33A Coding of Nominal Plurality", "53A Ordinal Numerals", "54A Distributive Numerals", "87A Order of Adjective and Noun", "85A Order of Adposition and Noun Phrase", "91A Order of Degree Word and Adjective",
"88A Order of Demonstrative and Noun", "86A Order of Genitive and Noun", "143A Order of Negative Morpheme and Verb", "89A Order of Numeral and Noun", "84A Order of Object Oblique and Verb",
"90A Order of Relative Clause and Noun", "107A Passive Constructions", "106A Reciprocal Constructions", "73A The Optative", "71A The Prohibitive", "70A The Morphological Imperative", "48A Person Marking on Adpositions",
"93A Position of Interrogative Phrases in Content Questions", "92A Position of Polar Question Particles", "59A Possessive Classification", "57A Position of Pronominal Possessive Affixes", "24A Locus of Marking in Possessive Noun Phrases",
"27A Reduplication", "67A The Future Tense", "66A The Past Tense", "65A Perfective/Imperfective Aspect", "102A Verbal Person Marking", "81A Order of Subject Object and Verb")
#clean up data
expect_false(any(duplicated(wals_source_data)))
#expect_false(any(duplicated(wals_source_data$language)))
names(wals_source_data)<- gsub("X","", names(wals_source_data))
names(wals_source_data)<- gsub("\\."," ", names(wals_source_data))
wals_source_info <- wals_source_data[,1:6]
wals_source_data <- wals_source_data[,-c(2:6)]
# load the list of recodings
recode_patterns <- read.csv("data/Recoding/recode_patterns_mixed.csv", stringsAsFactors=FALSE)
names(recode_patterns)[1]<-paste("wals.fname")
# extract the features that we don't need to recode
retained_wals_features <- filter(recode_patterns, is.na(recode.pattern))$wals.fname
retained_wals_features <- retained_wals_features[retained_wals_features %in% names(wals_source_data)]# Discard unused wals features
recode_patterns <- filter(recode_patterns, !is.na(recode.pattern))
recode_patterns <- recode_patterns[recode_patterns$wals.fname %in% names(wals_source_data),]
expect_false(any(duplicated(recode_patterns$new.fname)), info=paste0(
"Duplicated feature names:\n",
paste0("  ", recode_patterns$new.fname[duplicated(recode_patterns$new.fname)], collapse="\n")
))
recoded_wals_fnames <- c(retained_wals_features, recode_patterns$new.fname)
expect_true(all(retained_wals_features %in% names(wals_source_data)), info=paste0(
"Feature not found in WALS:\n",
paste0("  ", setdiff(retained_wals_features, names(wals_source_data)), collapse="\n")
))
# recode all the patterns
wals_recoded <- rowwise(recode_patterns) %>% do({
cat("Processing ", .$new.fname, "(", .$wals.fname, " recoded as ", .$recode.pattern, ")\n", sep="")
# check that the original variable is present in wals
expect_true(.$wals.fname %in% names(wals_source_data)[-1])
original_data <- as.character(wals_source_data[[.$wals.fname]])
# make a table of original values
expected_levels <- unlist(strsplit(.$wals.levels, "\n"))
expected_levels <- data.frame(
i = as.integer(gsub("^([0-9])+.+$", "\\1", expected_levels)),
level = gsub("^[0-9]+\\.? +", "", expected_levels),
stringsAsFactors=FALSE
)
expect_true(all(!is.na(expected_levels$i)))
expect_true(all(!is.na(expected_levels$level)))
# make sure that the WALS values are what we have in the table
#expect_true(setequal(expected_levels$level, na.omit(original_data)), info=
#              paste0("Expected:\n", paste0("  ", (expected_levels$level), collapse="\n"), "\n",
#                     "Got:\n",  paste0("  ", (unique(original_data)), collapse="\n"))
#)
# parse the recoding pattern
recoding_groups <- unlist(strsplit(.$recode.pattern, "-"))
recoding_groups <- strsplit(recoding_groups, "/") %>% lapply(as.integer)
# sanity checks
expect_true(length(recoding_groups)>1) # must have at least 2 recoding groups
expect_true(all(!is.na(unlist(recoding_groups)))) # can't have NA's
expect_true(all(unlist(recoding_groups) %in% expected_levels$i)) # must correspond to wals values
expect_false(any(duplicated(unlist(recoding_groups)))) # can't have any duplicates
# build the recodign table
recoded_levels <- unlist(strsplit(.$new.levels, "\n"))
expect_true(length(recoding_groups)==length(recoded_levels)) # must have at least 2 recoding groups
recoded_levels <- bind_rows(mapply(recoded_levels, recoding_groups, FUN=function(value, ii) {
data.frame(i = ii, new_level=as.character(value), stringsAsFactors=FALSE)
}, SIMPLIFY=FALSE))
level_table <- full_join(expected_levels, recoded_levels, by="i")
# sanity checks
expect_true(all(!is.na(level_table$level)))
# recode the data
recoded_data <- level_table$new_level[match(original_data, level_table$level)]
data.frame(
feature = .$new.fname,
language = wals_source_data$language,
value = recoded_data,
stringsAsFactors=FALSE)
}) %>%
pivot_wider(names_from = feature, values_from = value)
#  add the non-recoded variables
retained_data <- wals_source_data[c("language", retained_wals_features)]
wals_recoded <- full_join(wals_recoded, retained_data, by=c(language="language"))
# and merge it with the language list
wals_recoded <- full_join(wals_source_info, wals_recoded, by = "language")
###recode AUTOTYP features with 'mixed' category
np_structure <- combined_data[,-c(7:50)]
# load the mapping
NPMarking_mapping <- read_csv("data/Recoding/np_marking_feature_mapping.csv") %>%
set_names(c("NPStructureMarkingAssignmentType", "Feature"))
NPAgrCat_mapping <- read_csv("data/Recoding/NPAgrCat_feature_mapping.csv") %>%
set_names(c("NPStructureAgreementCategory", "Feature"))
# recode the NPMarking variable
NPMarking_recoded <- select(np_structure, language, NPStructureMarkingAssignmentType) %>%
# remove all entries where NPMarking is NA
filter(!is.na(NPStructureMarkingAssignmentType)) %>%
# bring in some language information
#left_join(select(register, LID, Glottocode, Language), by = "LID") %>%
# recode the variable using the mapping table
left_join(NPMarking_mapping, by = "NPStructureMarkingAssignmentType") %>%
# drop NPMarking as we don't need it anymore
select(-NPStructureMarkingAssignmentType) %>%
# unique features only
distinct() %>%
# pivot feature values to columns
mutate(value = TRUE) %>%
pivot_wider(names_from = Feature, values_fill = FALSE)
NPMarking_recoded<- select(NPMarking_recoded, -"NA")
# recode the NPAgrCat variable
NPAgrCat_recoded <- select(np_structure, language, NPStructureAgreementCategory) %>%
# remove all entries where NPAgrCat is NA
filter(!is.na(NPStructureAgreementCategory)) %>%
# bring in some language information
#left_join(select(register, LID, Glottocode, Language), by = "LID") %>%
# recode the variable using the mapping table
left_join(NPAgrCat_mapping, by = "NPStructureAgreementCategory") %>%
# drop NPAgrCat as we don't need it anymore
select(-NPStructureAgreementCategory) %>%
# unique features only
distinct() %>%
# pivot feature values to columns
mutate(value = TRUE) %>%
pivot_wider(names_from = Feature, values_fill = FALSE)
NPAgrCat_recoded<- select(NPAgrCat_recoded, -"NA")
# combime both recoded features
autotyp_recoded <- full_join(NPMarking_recoded, NPAgrCat_recoded, by=c(language="language"))
#  add the non-recoded variables
retained_autotyp_features <- select(np_structure, -NPStructureMarkingAssignmentType, -NPStructureAgreementCategory)
autotyp_recoded <- full_join(autotyp_recoded, retained_autotyp_features, by=c(language="language"))
autotyp_recoded %>% select(language, glottocode, family, area, latitude, longitude, everything())
recoded_data<- merge(wals_recoded, autotyp_recoded, by= c("language","glottocode", "family", "area", "longitude", "latitude")) %>%
relocate(language, glottocode, family, area, longitude, latitude)
#change feature names to short names
data<- recoded_data %>% rename(Rec.P = Reciprocal.Presence, RecRef.I = ReciprocalReflexive.Identical, RecRef.D = ReciprocalReflexive.Distinct, PossAff.P = PossAffixes.Presence, PossPre = PossPrefix, PossSuff = PossSuffix,
ComInst = "52A Comitatives and Instrumentals", NPconj = "63A Noun Phrase Conjunction", DefArt = "37A Definite Articles", IndefArt = "38A Indefinite Articles", PronomS = "101A Expression of Pronominal Subjects", IndefPron = "46A Indefinite Pronouns",
PronDem = "43A Third Person Pronouns and Demonstratives", DemDis = "41A Distance Contrasts in Demonstratives", PronAdnDem = "42A Pronominal and Adnominal Demonstratives", IntRef = "47A Intensifiers and Reflexive Pronouns", GenPron = "44A Gender Distinctions in Independent Personal Pronouns",
Gender = "32A Systems of Gender Assignment", "Gender.n" = "30A Number of Genders", NegMorph = "112A Negative Morphemes", NPlural = "33A Coding of Nominal Plurality", OrdNum = "53A Ordinal Numerals", DistNum = "54A Distributive Numerals",
AdpN = "85A Order of Adposition and Noun Phrase", DemN = "88A Order of Demonstrative and Noun", NegV = "143A Order of Negative Morpheme and Verb", OXV = "84A Order of Object Oblique and Verb", NVconj = "64A Nominal and Verbal Conjunction",
RelN = "90A Order of Relative Clause and Noun", Passive = "107A Passive Constructions", Optative= "73A The Optative", Prohibitive = "71A The Prohibitive", Imperative = "70A The Morphological Imperative", AdpPM = "48A Person Marking on Adpositions",
PolarQ = "92A Position of Polar Question Particles", PossClass = "59A Possessive Classification", PossLocus = "24A Locus of Marking in Possessive Noun Phrases", Reduplication = "27A Reduplication", Future = "67A The Future Tense", Past = "66A The Past Tense",
Aspect = "65A Perfective/Imperfective Aspect", Vper = "102A Verbal Person Marking", SOV = "81A Order of Subject Object and Verb", Agr.Gender = Gender, Alignment = DominantAlignment2ForCase, VInflCat = VerbInflectionMaxCategoryCount, NumClass.n = NumeralClassifiersCount,
NPHeadlessness = NPStructureHeadlessness, Agr.Number = Number, Agr.Case = Case, Agr.Def = Definiteness, Agr.State = State, Agr.none = none, Cons.state = "Construct state", Head.driven.agr = "Head-driven.agr", agr.class = "agr./class")
#the code collects all the posterior draws from the area coefficient,
#i.e. indirectly quantifying the probability to observe the associated
#feature in the area. The coefficient column says which variable and category it is.
data<- read.csv("data/Processed_data/reg_data.csv")
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
variables <- colnames(reg_data)[7:76]
results.list <- list()
ex.prior <- c(prior_string("normal(0,1)", class="b"))
options(brms.backend = "cmdstanr")
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
reg_data
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
reg_data
#regression model, runs on brms version 2.19.0
for(u in 1:length(variables)){
print(u)
brmsformula <- as.formula(paste(variables[u], '~ area + (1|family)'))
fit <- brm(
formula= brmsformula,
family= categorical(link="logit"),
prior= ex.prior,
data= reg_data,
iter = 5000,
cores=4,
control = list(adapt_delta = 0.9999999))
results.list[[u]] <- fit
}
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
reg_data<- read.csv("data/Processed_data/reg_data.csv", encoding="UTF-8", na.strings=c(""," ","NA","\n"))
